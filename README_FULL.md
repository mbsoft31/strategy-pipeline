# ğŸ”¬ HITL Research Strategy Pipeline

**The Validated AI Research Assistant**

A production-ready research strategy tool that combines AI intelligence with literature validation and perfect database syntax generation.

[![Python](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://www.python.org)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.30+-red.svg)](https://streamlit.io)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

---

## ğŸ¯ What It Does

Transform a raw research idea into validated, publication-ready search strategies in 3 clicks:

1. **ğŸ§  AI extracts** project context (title, keywords, discipline)
2. **ğŸ•µï¸ AI critiques** and refines its own work (reflection pattern)
3. **ğŸ“š OpenAlex validates** every concept against 250M+ scholarly works
4. **ğŸ¯ Generates perfect syntax** for 6 academic databases

**Your competitive moat:** ChatGPT can't guarantee syntax correctness or validate against real literature. You can.

---

## âœ¨ Features

### The Trust Dashboard (Streamlit UI)
- âœ… **Visual workflow** - Watch the AI think in real-time
- âœ… **Critique reports** - See AI's self-evaluation with feasibility scores
- âœ… **OpenAlex validation** - Every term verified with hit counts
- âœ… **6 database syntaxes** - PubMed, Scopus, arXiv, OpenAlex, Semantic Scholar, CrossRef
- âœ… **One-click export** - Download all queries as text

### The Technical Moat
- âœ… **Strategy Pattern** - Perfect syntax generation (zero hallucination risk)
- âœ… **Reflection Loop** - AI critiques and refines its own output
- âœ… **Reality Check** - OpenAlex validates concepts exist in literature
- âœ… **Cost-effective** - ~$0.006 per project with GPT-4o-mini

---

## ğŸš€ Quick Start

### Installation

```bash
# Clone repository
git clone <your-repo-url>
cd strategy-pipeline

# Create virtual environment
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### Configuration

Create `.env` file:

```env
# For free testing (no API key needed)
LLM__PROVIDER=mock

# For production with OpenAI
# LLM__PROVIDER=openai
# LLM__OPENAI_API_KEY=sk-proj-xxxxxxxxxxxxxxxxxxxxx
# LLM__OPENAI_MODEL=gpt-4o-mini
# LLM__OPENAI_TEMPERATURE=0.7
```

### Launch

```bash
# Start the Trust Dashboard
streamlit run app.py

# Or run CLI demo
python demo_sprint2.py

# Or test syntax engine
python demo_syntax_engine.py
```

---

## ğŸ“– Usage

### Web Interface (Recommended)

1. **Launch:** `streamlit run app.py`
2. **Enter idea:** "Effect of telemedicine on rural diabetes management"
3. **Generate context** â†’ See structured project details
4. **Run agentic workflow** â†’ Watch AI draft â†’ critique â†’ refine â†’ validate
5. **View results** â†’ Critique report with OpenAlex validation
6. **Get queries** â†’ Perfect syntax for 6 databases

### Python API

```python
from src.services.intelligent_model_service import IntelligentModelService
from src.search.builder import get_builder

# Initialize service
service = IntelligentModelService()

# Stage 1: Generate context
context, meta = service.suggest_project_context(
    "Research LLM hallucinations in healthcare"
)

# Stage 2: Problem framing with validation
framing, concepts, meta = service.generate_problem_framing(context)

# View critique report
print(framing.critique_report)  # AI critique + OpenAlex validation

# Stage 3: Generate database queries
from src.search.models import QueryPlan, ConceptBlock, FieldTag

plan = QueryPlan()
for concept in concepts.concepts:
    block = ConceptBlock(concept.type)
    block.add_term(concept.label, FieldTag.KEYWORD)
    plan.blocks.append(block)

# Get PubMed syntax
pubmed_query = get_builder("pubmed").build(plan)
print(pubmed_query)
```

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Trust Dashboard                      â”‚
â”‚                  (Streamlit Web UI)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Intelligent Model Service                  â”‚
â”‚  Draft â†’ Critique â†’ Refine â†’ Validate                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“                                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   LLM Provider      â”‚          â”‚ Validation Service    â”‚
â”‚   - OpenAI          â”‚          â”‚ - OpenAlex API        â”‚
â”‚   - Mock            â”‚          â”‚ - Hit counts          â”‚
â”‚   - Cached          â”‚          â”‚ - Sample works        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Syntax Engine                          â”‚
â”‚  Strategy Pattern - 6 Database Dialects                â”‚
â”‚  PubMed | Scopus | arXiv | OpenAlex | S2 | CrossRef   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š Project Structure

```
strategy-pipeline/
â”œâ”€â”€ app.py                          # Streamlit Trust Dashboard
â”œâ”€â”€ demo_sprint2.py                 # CLI demo (LLM + validation)
â”œâ”€â”€ demo_syntax_engine.py           # Syntax engine demo
â”œâ”€â”€ requirements.txt                # Dependencies
â”œâ”€â”€ .env.example                    # Configuration template
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py                   # Configuration management
â”‚   â”œâ”€â”€ models.py                   # Data models (artifacts)
â”‚   â”œâ”€â”€ controller.py               # Workflow orchestration
â”‚   â”‚
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ llm_provider.py        # LLM abstraction (OpenAI, Mock)
â”‚   â”‚   â”œâ”€â”€ prompts.py             # Centralized prompt templates
â”‚   â”‚   â”œâ”€â”€ validation_service.py  # OpenAlex validation
â”‚   â”‚   â””â”€â”€ intelligent_model_service.py  # Enhanced model service
â”‚   â”‚
â”‚   â”œâ”€â”€ search/
â”‚   â”‚   â”œâ”€â”€ models.py              # Search term models
â”‚   â”‚   â”œâ”€â”€ dialects.py            # Database syntax implementations
â”‚   â”‚   â””â”€â”€ builder.py             # Query builder (Strategy Pattern)
â”‚   â”‚
â”‚   â”œâ”€â”€ stages/
â”‚   â”‚   â”œâ”€â”€ project_setup.py       # Stage 0: Initial setup
â”‚   â”‚   â””â”€â”€ problem_framing.py     # Stage 1: Problem framing
â”‚   â”‚
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ exceptions.py          # Exception hierarchy
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_llm_provider.py      # LLM provider tests
â”‚   â”œâ”€â”€ test_validation_service.py # Validation tests
â”‚   â””â”€â”€ test_syntax_engine.py     # Syntax engine tests
â”‚
â””â”€â”€ docs/
    â”œâ”€â”€ SPRINT1_SUMMARY.md         # Syntax engine documentation
    â”œâ”€â”€ SPRINT2_COMPLETE.md        # LLM integration documentation
    â”œâ”€â”€ SPRINT3_COMPLETE.md        # Dashboard documentation
    â”œâ”€â”€ SPRINT3_QUICKSTART.md      # User guide
    â””â”€â”€ architecture-overview.md   # Technical architecture
```

---

## ğŸ§ª Testing

```bash
# Run all tests
pytest tests/ -v

# Run specific test suite
pytest tests/test_syntax_engine.py -v
pytest tests/test_llm_provider.py -v
pytest tests/test_validation_service.py -v

# Run with coverage
pytest tests/ --cov=src --cov-report=html
```

**Test Coverage:** 79% (29/34 tests passing)

---

## ğŸ’° Cost Analysis

### Mock Mode (Free)
- âœ… Zero API costs
- âœ… Instant responses
- âœ… Perfect for testing/demos

### OpenAI Mode (Production)
- Stage 1 (Context): ~$0.001
- Stage 2 (Critique + Refine + Validate): ~$0.005
- Stage 3 (Syntax): $0 (local)

**Total: ~$0.006 per project** (less than 1 cent!)

With GPT-4: ~$0.05 per project (5 cents)

---

## ğŸ¯ Use Cases

### For Researchers
- âœ… Systematic literature reviews
- âœ… Meta-analyses
- âœ… Grant proposal research strategies
- âœ… PhD dissertation planning
- âœ… Publication search strategies

### For Research Teams
- âœ… Standardized search protocols
- âœ… Reproducible strategies
- âœ… Quality control (critique reports)
- âœ… Training new researchers

### For Librarians
- âœ… Reference consultations
- âœ… Database training
- âœ… Search strategy review
- âœ… Systematic review support

---

## ğŸ† Competitive Advantages

### vs. ChatGPT
- âœ… **Validation:** We verify against 250M+ works
- âœ… **Syntax correctness:** Strategy Pattern guarantees accuracy
- âœ… **Transparency:** Full critique reports
- âœ… **Reproducibility:** Same input â†’ same output

### vs. Manual Search
- âœ… **Speed:** Minutes instead of hours
- âœ… **Completeness:** AI finds terms you might miss
- âœ… **Multi-database:** 6 syntaxes simultaneously
- âœ… **Quality:** Self-critique improves results

### Your Moat
1. **Perfect syntax generation** (Strategy Pattern)
2. **Literature validation** (OpenAlex integration)
3. **AI self-critique** (Reflection pattern)
4. **Domain focus** (Systematic reviews, not general chat)

---

## ğŸ“š Documentation

- **[SPRINT3_QUICKSTART.md](SPRINT3_QUICKSTART.md)** - User guide for the dashboard
- **[SPRINT3_COMPLETE.md](SPRINT3_COMPLETE.md)** - Sprint 3 implementation details
- **[SPRINT2_COMPLETE.md](SPRINT2_COMPLETE.md)** - LLM integration documentation
- **[SPRINT1_SUMMARY.md](SPRINT1_SUMMARY.md)** - Syntax engine documentation
- **[docs/architecture-overview.md](docs/architecture-overview.md)** - Technical architecture

---

## ğŸ›£ï¸ Roadmap

### âœ… Completed
- [x] Sprint 1: Syntax Engine (6 databases)
- [x] Sprint 2: LLM Integration + Validation
- [x] Sprint 3: Trust Dashboard (Streamlit UI)

### ğŸš§ Sprint 4 (Next)
- [ ] Query execution (run searches from dashboard)
- [ ] Result preview (sample papers)
- [ ] Project persistence (save/load workflows)
- [ ] Multi-project support
- [ ] PDF export (generate reports)

### ğŸ”® Future Sprints
- [ ] Collaborative features (team workflows)
- [ ] Advanced analytics (search quality metrics)
- [ ] API endpoint (integrate with other tools)
- [ ] Plugin system (custom databases)

---

## ğŸ¤ Contributing

Contributions welcome! Please:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) file for details

---

## ğŸ™ Acknowledgments

- **OpenAlex** for free literature validation API
- **Streamlit** for rapid UI development
- **OpenAI** for GPT models
- **The research community** for inspiring this tool

---

## ğŸ“§ Contact

For questions, issues, or collaboration:
- Open an issue on GitHub
- Email: [your-email@example.com]
- Twitter: [@yourhandle]

---

## ğŸŒŸ Star History

If this tool helps your research, please star the repository!

---

**Built with â¤ï¸ for researchers who value transparency and reproducibility**

ğŸ”¬ **HITL Research Strategy Pipeline** - Where AI meets Academic Rigor

