"""
Orchestrator Agent - The "Brain" of Autonomous Research.

This agent takes a research question and autonomously:
1. Analyzes the question to understand intent
2. Generates effective search queries for academic databases
3. Selects appropriate databases to search
4. Executes searches using the SearchService
5. Returns collected results (synthesis happens in SynthesizerAgent)

This is the intelligence layer that makes the system "autonomous".
"""

import logging
from typing import List, Dict, Optional, Tuple
from dataclasses import dataclass

from src.services.llm_provider import get_llm_provider
from src.services.search_service import get_search_service, SearchResultsSummary

logger = logging.getLogger(__name__)


@dataclass
class SearchStrategy:
    """A search strategy generated by the orchestrator."""
    databases: List[str]  # Which databases to search
    queries: List[str]    # What queries to run
    reasoning: str        # Why this strategy was chosen
    max_results: int = 50  # How many results per query


@dataclass
class ResearchResults:
    """Results from autonomous research execution."""
    question: str
    strategy: SearchStrategy
    search_results: List[SearchResultsSummary]
    total_papers: int
    execution_time: float
    errors: List[str]


class OrchestratorAgent:
    """
    The Orchestrator Agent coordinates autonomous research.

    This is the "thinking" part of the system - it uses LLMs to understand
    research questions and plan effective search strategies.

    Philosophy:
    - The agent should feel "intelligent" - it reasons about what to search
    - It should handle vague questions by clarifying them into concrete searches
    - It should select databases based on the domain (e.g., arXiv for CS, OpenAlex for broad)
    """

    def __init__(self):
        """Initialize the orchestrator with LLM and search capabilities."""
        self.llm = get_llm_provider()
        self.search_service = get_search_service()
        logger.info("OrchestratorAgent initialized")

    def research(self, question: str, max_results_per_query: int = 50) -> ResearchResults:
        """
        Autonomously research a question.

        This is the main entry point - give it a question, get back papers.

        Args:
            question: Research question in natural language
                     e.g., "What are effective prompt engineering techniques?"
            max_results_per_query: Maximum papers to fetch per search query

        Returns:
            ResearchResults with strategy, papers, and metadata

        Example:
            >>> agent = OrchestratorAgent()
            >>> results = agent.research("What are LLM hallucination detection methods?")
            >>> print(f"Found {results.total_papers} papers")
            >>> print(f"Strategy: {results.strategy.reasoning}")
        """
        import time
        start_time = time.time()

        logger.info(f"Starting autonomous research for: {question}")

        # Step 1: Generate search strategy using LLM
        logger.info("Generating search strategy...")
        strategy = self._generate_search_strategy(question, max_results_per_query)

        logger.info(f"Strategy: {strategy.reasoning}")
        logger.info(f"Will search {len(strategy.databases)} databases with {len(strategy.queries)} queries")

        # Step 2: Execute searches
        logger.info("Executing searches...")
        search_results = []
        errors = []

        for database in strategy.databases:
            for query in strategy.queries:
                try:
                    result = self.search_service.execute_search(
                        database=database,
                        query=query,
                        max_results=strategy.max_results
                    )

                    if result.error:
                        errors.append(f"{database}/{query}: {result.error}")
                        logger.warning(f"Search failed: {database}/{query} - {result.error}")
                    else:
                        search_results.append(result)
                        logger.info(f"Search succeeded: {database}/{query} - {result.total_hits} results")

                except Exception as e:
                    error_msg = f"{database}/{query}: {str(e)}"
                    errors.append(error_msg)
                    logger.error(f"Search exception: {error_msg}", exc_info=True)

        # Step 3: Calculate totals
        total_papers = sum(r.total_hits for r in search_results)
        execution_time = time.time() - start_time

        logger.info(f"Research complete: {total_papers} papers in {execution_time:.2f}s")

        return ResearchResults(
            question=question,
            strategy=strategy,
            search_results=search_results,
            total_papers=total_papers,
            execution_time=execution_time,
            errors=errors
        )

    def _generate_search_strategy(self, question: str, max_results: int) -> SearchStrategy:
        """
        Use LLM to generate an effective search strategy.

        This is where the "intelligence" happens - the LLM analyzes the question
        and decides:
        - Which academic databases to use
        - What search queries to construct
        - Why this strategy makes sense

        Args:
            question: Research question
            max_results: Max results per query

        Returns:
            SearchStrategy with databases, queries, and reasoning
        """
        system_prompt = """You are a research strategist helping design effective academic literature searches.

Available databases:
- openalex: Open scholarly index (comprehensive, all fields)
- arxiv: Preprint repository (CS, physics, math, strong in AI/ML)
- crossref: DOI metadata (published papers, journals)
- semanticscholar: AI-powered search (good for CS, citation analysis)

Your task: Given a research question, generate an effective search strategy.

Guidelines:
- Choose 1-3 databases based on the question's domain
- Generate 1-3 search queries (different angles on the topic)
- Keep queries concise but specific
- Use boolean operators if needed (AND, OR, NOT)
- Explain your reasoning

Respond with valid JSON only:
{
    "databases": ["openalex", "arxiv"],
    "queries": ["prompt engineering techniques", "few-shot learning methods"],
    "reasoning": "Using arXiv for recent AI/ML papers and OpenAlex for broader coverage..."
}"""

        user_prompt = f"""Research Question: {question}

Generate a search strategy that will find the most relevant academic papers."""

        try:
            response = self.llm.generate(system_prompt, user_prompt)
            strategy_dict = self.llm.clean_json_response(response)

            # Validate databases
            available_dbs = self.search_service.get_available_databases()
            databases = [db for db in strategy_dict.get('databases', [])
                        if db in available_dbs]

            if not databases:
                # Fallback: use OpenAlex (most comprehensive)
                logger.warning("No valid databases in strategy, defaulting to OpenAlex")
                databases = ['openalex']

            queries = strategy_dict.get('queries', [])
            if not queries:
                # Fallback: use the question as-is
                logger.warning("No queries in strategy, using question as query")
                queries = [question]

            reasoning = strategy_dict.get('reasoning', 'Generated by LLM')

            return SearchStrategy(
                databases=databases,
                queries=queries,
                reasoning=reasoning,
                max_results=max_results
            )

        except Exception as e:
            # Fallback strategy if LLM fails
            logger.error(f"Failed to generate strategy with LLM: {e}", exc_info=True)
            logger.warning("Using fallback strategy")

            return SearchStrategy(
                databases=['openalex'],  # Most reliable, comprehensive
                queries=[question],       # Use question as-is
                reasoning=f"Fallback strategy (LLM failed: {str(e)})",
                max_results=max_results
            )

    def explain_strategy(self, strategy: SearchStrategy) -> str:
        """
        Generate a human-readable explanation of the search strategy.

        Args:
            strategy: The SearchStrategy to explain

        Returns:
            Formatted string explaining the strategy
        """
        lines = [
            "ğŸ¯ Search Strategy",
            "=" * 60,
            "",
            f"Databases: {', '.join(strategy.databases)}",
            f"Queries: {len(strategy.queries)}",
            "",
            "Reasoning:",
            f"  {strategy.reasoning}",
            "",
            "Search Queries:"
        ]

        for i, query in enumerate(strategy.queries, 1):
            lines.append(f"  {i}. {query}")

        lines.append("")
        lines.append(f"Max results per query: {strategy.max_results}")

        return "\n".join(lines)


# Convenience function for quick usage
def autonomous_research(question: str, max_results: int = 50) -> ResearchResults:
    """
    One-line autonomous research function.

    Args:
        question: Research question
        max_results: Max results per query

    Returns:
        ResearchResults

    Example:
        >>> results = autonomous_research("What is retrieval augmented generation?")
        >>> print(f"Found {results.total_papers} papers")
    """
    agent = OrchestratorAgent()
    return agent.research(question, max_results)

