# HITL Pipeline Configuration
# Copy this file to .env and fill in your values

# ==========================================
# Environment
# ==========================================
ENVIRONMENT=development
DEBUG=False
LOG_LEVEL=INFO

# ==========================================
# LLM Provider Configuration
# ==========================================

# Provider: openai, mock, or cached
LLM__PROVIDER=mock

# OpenAI Settings (required if provider=openai)
# Get your API key from https://platform.openai.com/api-keys
LLM__OPENAI_API_KEY=sk-proj-xxxxxxxxxxxxxxxxxxxxx
LLM__OPENAI_MODEL=gpt-4o-mini
LLM__OPENAI_TEMPERATURE=0.7
LLM__OPENAI_MAX_TOKENS=

# Rate Limiting
LLM__RATE_LIMIT=10.0
LLM__RATE_LIMIT_BURST=20

# Retry Configuration
LLM__MAX_RETRIES=3
LLM__RETRY_BASE_DELAY=1.0
LLM__RETRY_MAX_DELAY=60.0

# Timeout
LLM__TIMEOUT=30

# Cache Settings
LLM__CACHE_DIR=.cache/llm
LLM__CACHE_ENABLED=False

# ==========================================
# Validation Services (OpenAlex)
# ==========================================

# Your email for polite OpenAlex requests (recommended)
VALIDATION__OPENALEX_MAILTO=your.email@example.com
VALIDATION__OPENALEX_RATE_LIMIT=9.0
VALIDATION__OPENALEX_TIMEOUT=30
VALIDATION__OPENALEX_CACHE_ENABLED=True
VALIDATION__OPENALEX_CACHE_TTL=86400

# ==========================================
# Pipeline Settings
# ==========================================

# Data directory
DATA_DIR=./data

# Error handling: fail fast or graceful degradation
FAIL_ON_LLM_ERROR=True

